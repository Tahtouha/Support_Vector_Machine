# -*- coding: utf-8 -*-
"""ZERNADJI_TAHA_TP_SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kLd-bsNBf-1u09JZJBxOKGV1nVXnLUDl
"""

#import library
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import svm, datasets
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

"""#Read and arrange data

"""

#read data
data = pd.read_csv("/content/sample_data/SVM_DATASET.csv")


Versicolor = data.loc[data['variety'] == 'Versicolor']
Virginica = data.loc[data['variety'] == 'Virginica']
Setosa = data.loc[data['variety'] == 'Setosa']

"""# Plot method"""

def make_meshgrid(x, y, h=.02):
    x_min, x_max = x.min() - 1, x.max() + 1
    y_min, y_max = y.min() - 1, y.max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    return xx, yy

def plot_contours(ax, clf, xx, yy, **params):
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    out = ax.contourf(xx, yy, Z, **params)
    return out

"""# Deux clans et deux attribus"""

clans = [Versicolor, Virginica]
clan_concat = pd.concat(clans)

data1 = clan_concat.replace({"variety":  {"Setosa":1,"Versicolor":2, "Virginica":3}})

X = data1.drop(['variety','sepal.width','petal.width'], axis = 1)

Y = data1['variety']

#split data 
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)

svm = SVC(kernel="linear")
clf = svm.fit(X_train,Y_train)

pred = svm.predict(X_test)
print("Precision du model:")
svm.score(X_test,Y_test)

"""En utlisant deux clan (Versicolor, Virginica) et deux attribus (sepal.length, petal.length), on remarque une grade précision ou score correspondant a 93%, cela veux dir qu'on a une séparation caire entre les données."""

fig, ax = plt.subplots()
# title for the plots
title = ('svm iris')
# Set-up grid for plotting.
X0, X1 = X["sepal.length"], X["petal.length"]
xx, yy = make_meshgrid(X0, X1)

plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)
ax.scatter(X0, X1, c=Y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')
ax.set_ylabel('y label here')
ax.set_xlabel('x label here')
ax.set_xticks(())
ax.set_yticks(())
ax.set_title(title)
ax.legend()
plt.show()

"""Comme mentionné auparavent notre modèle sépare correctement les données, avec une certaine marge d'erreur, cette erreur est les 7% menquan du score.

# Trois clans et deux attribus
"""

clans = [Setosa, Versicolor, Virginica]
clan_concat = pd.concat(clans)

data1 = clan_concat.replace({"variety":  {"Setosa":1,"Versicolor":2, "Virginica":3}})

X = data1.drop(['variety','sepal.width','petal.width'], axis = 1)

Y = data1['variety']

#split data 
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)

svm = SVC(kernel="linear")
clf = svm.fit(X_train,Y_train)

pred = svm.predict(X_test)
print("Precision du model:")
svm.score(X_test,Y_test)

"""Avec 3 calan on remarque une précision inférieur a celle du modèle entrainné avec 2 clan, la précision est de 91%, on devrais s'attendre a plus de point du testing classifier incorrectement."""

fig, ax = plt.subplots()
# title for the plots
title = ('svm iris')
# Set-up grid for plotting.
X0, X1 = X["sepal.length"], X["petal.length"]
xx, yy = make_meshgrid(X0, X1)

plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)
ax.scatter(X0, X1, c=Y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')
ax.set_ylabel('y label here')
ax.set_xlabel('x label here')
ax.set_xticks(())
ax.set_yticks(())
ax.set_title(title)
ax.legend()
plt.show()

"""Comme prévu, on retrouve plus d'ambiguité entre la classe blanche et rouge, cette erreur comme la première experience correspond au point classifier incorrectement, ce la est aussi induqué comme étant un séparation pas clair entre les classes

# Deux clans et Quatre attributs
"""

clans = [Setosa, Virginica]
clan_concat = pd.concat(clans)

data1 = clan_concat.replace({"variety":  {"Setosa":1,"Versicolor":2, "Virginica":3}})

X = data1.drop(['variety'], axis = 1)

Y = data1['variety']

#split data 
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.40)

svm = SVC(kernel="linear")
clf = svm.fit(X_train,Y_train)

pred = svm.predict(X_test)
print("Precision du model:")
svm.score(X_test,Y_test)

"""Nous travaillions maintenant avec des dimentions supérieurs a 3, donc pour faire un plot et visualiser nos résulat il faudra trouver une solution, une de ses solution est de faire different plot pour toute paire possible des dimentions utilisé, la deuxième methode, celle qu'on vas utliser et la réduction de dimentionalité. J'ai opté our les PCA pour réduire les dimention de notre X de 4 a 2 pour faire un plot et visulaier la séparation."""

import numpy as np
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
principalComponents = pca.fit_transform(X)
principalDf = pd.DataFrame(data = principalComponents
             , columns = ['PC_1', 'PC_2'])

fig, ax = plt.subplots()
# title for the plots
title = ('svm iris')
# Set-up grid for plotting.
X0, X1 = principalDf["PC_1"], principalDf["PC_2"]
xx, yy = make_meshgrid(X0, X1)

#plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)
ax.scatter(X0, X1, c=Y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')
ax.set_ylabel('y label here')
ax.set_xlabel('x label here')
ax.set_xticks(())
ax.set_yticks(())
ax.set_title(title)
ax.legend()
plt.show()

"""# Partie 2
Dans cette partie nous allons utiliser deux datasets de UCI, le premier correspond a la base de detection de programme malveillants. la deuxième est utiliser pour la reconnaissance de lettres.

On vas commencer par la BDD de detection de malware.
"""

#read data
data_malware_detect = pd.read_csv("/content/sample_data/uci_malware_detection.csv")

data_malware_detect

X = data_malware_detect.drop(['Label'], axis = 1)

Y = data_malware_detect['Label']

#split data 
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)

svm = SVC(kernel="linear")
clf = svm.fit(X_train,Y_train)

pred = svm.predict(X_test)
print("Precision du model:")
svm.score(X_test,Y_test)

#Test de généralisation
malware_detection_report = classification_report(Y_test,pred)
print(malware_detection_report)

"""Comme le premier modèle pour mesurer la précision du modèle on calcule son score en utlisant un testing set, qui une partie du dataset que le modèle n'as pas encore vu, sela nous permet de voir comment le modèle gère les nouvelles données.

Using letter recognition dataset
"""

letter_recognition = pd.read_csv("/content/sample_data/letter-recognition.csv")

letter_recognition

X = letter_recognition.drop(['letter'], axis = 1)

Y = letter_recognition['letter']

#split data 
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)

svm = SVC(kernel="linear")
clf = svm.fit(X_train,Y_train)

pred = svm.predict(X_test)
print("Precision du model:")
svm.score(X_test,Y_test)

#Test de généralisation
letter_recognition_report = classification_report(Y_test,pred)
print(letter_recognition_report)

Animals_10 = pd.read_csv("/content/sample_data/SVM_DATASET.csv")

X = Animals_10.drop(['Classes'], axis = 1)

Y = Animals_10['Classes']

#split data 
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)

svm = SVC(kernel="linear")
clf = svm.fit(X_train,Y_train)

pred = svm.predict(X_test)
print("Precision du model:")
svm.score(X_test,Y_test)

#Test de généralisation
Animals_report = classification_report(Y_test,pred)
print(Animals_report)